# 智能上下文管理系统

## 概述

Luminous LLM Chat 提供了先进的上下文管理系统，支持32k上下文长度、智能压缩和对话恢复功能。

## 核心特性

### 32k上下文长度
- 默认支持32,768个token的上下文长度
- 相比传统的4k-8k上下文，可以保持更长的对话记忆
- 适合复杂的多轮对话和深度讨论

### 智能上下文压缩
当对话超过上下文限制时，系统会自动进行智能压缩：

1. **保留重要信息**: 系统消息和最近的对话内容始终保留
2. **AI驱动压缩**: 使用LLM将旧对话压缩成简洁摘要
3. **无缝体验**: 压缩过程对用户透明，对话连续性不受影响
4. **回退机制**: 如果压缩失败，自动回退到传统的删除模式

### 压缩通知系统
当对话达到最大上下文长度时，系统会智能提醒用户：

**用户体验**：
- **提前通知**: 在压缩开始前显示友好提示
- **清晰说明**: "⚠️ 已达到最大上下文长度，您的之前上下文将被压缩"
- **可配置**: 支持开启/关闭通知功能

**通知时机**：
- 当消息数量达到 `maxContextLength` 设置值时触发
- 在添加新消息之前显示，让用户了解即将发生的变化

### 自定义压缩模型
支持为上下文压缩任务配置专用模型，实现成本优化：

**模型策略**：
- **聊天模型**: 使用高质量模型（如 gpt-4）获得最佳对话体验
- **压缩模型**: 使用经济模型（如 gpt-3.5-turbo）降低压缩成本
- **智能回退**: 未配置压缩模型时自动使用当前聊天模型

### 对话恢复功能
- 使用 `/llmchat resume` 命令快速恢复上次对话
- 自动恢复对话历史、上下文和提示词模板设置
- 显示最近消息预览，帮助快速回忆对话内容
- 智能检测当前对话状态，避免意外覆盖

## 配置说明

### 基本配置
```json
{
  "maxContextLength": 32768,              // 最大上下文长度（token数）
  "compressionModel": "gpt-3.5-turbo",   // 压缩专用模型（空字符串=使用当前模型）
  "enableCompressionNotification": true  // 启用压缩通知
}
```

### 配置项详解

| 配置项 | 类型 | 默认值 | 说明 |
|--------|------|--------|------|
| `compressionModel` | String | `""` | 指定用于压缩上下文的模型。空字符串表示使用当前聊天模型 |
| `enableCompressionNotification` | Boolean | `true` | 是否在压缩时显示提示消息 |
| `maxContextLength` | Integer | `32768` | 最大上下文长度，超过时触发压缩 |

### 使用建议
- **成本优化**: 设置 `compressionModel` 为更便宜的模型（如 gpt-3.5-turbo）
- **用户体验**: 新用户建议开启 `enableCompressionNotification`
- **高级用户**: 熟悉系统后可关闭通知减少干扰

## 使用示例

### 压缩通知示例
```
# 当对话接近上下文限制时
/llmchat 继续我们的讨论...

# 系统自动显示：
⚠️ 已达到最大上下文长度，您的之前上下文将被压缩

# 压缩完成后（如果启用通知）：
✅ 上下文压缩完成，对话历史已优化
```

### 对话恢复示例
```
/llmchat resume
# 自动恢复上次对话的所有内容，包括上下文和提示词模板
# 显示最近3条消息作为预览
```

**注意：** resume命令只能在当前对话为空时使用。如果当前已有对话内容，需要先使用 `/llmchat clear` 清空。

### 配置示例
```json
{
  "currentModel": "gpt-4",           // 聊天使用高质量模型
  "compressionModel": "gpt-3.5-turbo", // 压缩使用经济模型
  "enableCompressionNotification": true // 启用压缩通知
}
```

## 技术实现

### 压缩算法
1. 识别系统消息和用户对话消息
2. 保留系统消息和最近的对话内容
3. 将需要压缩的消息发送给LLM进行摘要
4. 用摘要替换原始消息，保持对话连续性

### 性能优化
- 异步压缩处理，不阻塞用户操作
- 智能缓存机制，避免重复压缩
- 压缩失败时的优雅降级

### 安全考虑
- 压缩过程中保护敏感信息
- 压缩模型的权限控制
- 压缩历史的审计日志
