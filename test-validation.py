#!/usr/bin/env python3
"""
LLMChatMod Function Calling æµ‹è¯•éªŒè¯è„šæœ¬
é€šè¿‡é™æ€åˆ†æéªŒè¯æµ‹è¯•ä»£ç çš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§
"""

import os
import re
from pathlib import Path

class TestValidator:
    def __init__(self):
        self.test_dir = Path("src/test/java/com/riceawa/llm")
        self.results = {
            'total_test_files': 0,
            'total_test_methods': 0,
            'test_categories': {},
            'issues': [],
            'coverage': {}
        }
    
    def validate_all_tests(self):
        """éªŒè¯æ‰€æœ‰æµ‹è¯•æ–‡ä»¶"""
        print("ğŸ§ª å¼€å§‹éªŒè¯ LLMChatMod Function Calling æµ‹è¯•...")
        print("=" * 60)
        
        if not self.test_dir.exists():
            print("âŒ æµ‹è¯•ç›®å½•ä¸å­˜åœ¨")
            return False
        
        # éªŒè¯æµ‹è¯•æ–‡ä»¶ç»“æ„
        self.validate_test_structure()
        
        # éªŒè¯å„ä¸ªæµ‹è¯•æ–‡ä»¶
        self.validate_core_tests()
        self.validate_function_tests()
        self.validate_service_tests()
        self.validate_integration_tests()
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
        
        return len(self.results['issues']) == 0
    
    def validate_test_structure(self):
        """éªŒè¯æµ‹è¯•ç›®å½•ç»“æ„"""
        print("ğŸ“ éªŒè¯æµ‹è¯•ç›®å½•ç»“æ„...")
        
        expected_dirs = [
            'core',
            'function',
            'function/impl', 
            'service',
            'integration'
        ]
        
        for dir_name in expected_dirs:
            dir_path = self.test_dir / dir_name
            if dir_path.exists():
                print(f"  âœ… {dir_name}/ ç›®å½•å­˜åœ¨")
            else:
                print(f"  âŒ {dir_name}/ ç›®å½•ç¼ºå¤±")
                self.results['issues'].append(f"ç¼ºå¤±ç›®å½•: {dir_name}")
    
    def validate_core_tests(self):
        """éªŒè¯æ ¸å¿ƒç±»æµ‹è¯•"""
        print("\nğŸ”§ éªŒè¯æ ¸å¿ƒç±»æµ‹è¯•...")
        
        core_tests = [
            'LLMConfigTest.java',
            'LLMMessageTest.java'
        ]
        
        for test_file in core_tests:
            file_path = self.test_dir / 'core' / test_file
            if file_path.exists():
                methods = self.count_test_methods(file_path)
                print(f"  âœ… {test_file}: {methods} ä¸ªæµ‹è¯•æ–¹æ³•")
                self.results['test_categories']['core'] = self.results['test_categories'].get('core', 0) + methods
                self.results['total_test_files'] += 1
                self.results['total_test_methods'] += methods
            else:
                print(f"  âŒ {test_file} æ–‡ä»¶ç¼ºå¤±")
                self.results['issues'].append(f"ç¼ºå¤±æ–‡ä»¶: core/{test_file}")
    
    def validate_function_tests(self):
        """éªŒè¯å‡½æ•°ç³»ç»Ÿæµ‹è¯•"""
        print("\nâš™ï¸ éªŒè¯å‡½æ•°ç³»ç»Ÿæµ‹è¯•...")
        
        function_tests = [
            'FunctionRegistryTest.java',
            'impl/WorldInfoFunctionTest.java'
        ]
        
        for test_file in function_tests:
            file_path = self.test_dir / 'function' / test_file
            if file_path.exists():
                methods = self.count_test_methods(file_path)
                print(f"  âœ… {test_file}: {methods} ä¸ªæµ‹è¯•æ–¹æ³•")
                self.results['test_categories']['function'] = self.results['test_categories'].get('function', 0) + methods
                self.results['total_test_files'] += 1
                self.results['total_test_methods'] += methods
            else:
                print(f"  âŒ {test_file} æ–‡ä»¶ç¼ºå¤±")
                self.results['issues'].append(f"ç¼ºå¤±æ–‡ä»¶: function/{test_file}")
    
    def validate_service_tests(self):
        """éªŒè¯æœåŠ¡å±‚æµ‹è¯•"""
        print("\nğŸŒ éªŒè¯æœåŠ¡å±‚æµ‹è¯•...")
        
        service_tests = [
            'OpenAIServiceTest.java'
        ]
        
        for test_file in service_tests:
            file_path = self.test_dir / 'service' / test_file
            if file_path.exists():
                methods = self.count_test_methods(file_path)
                print(f"  âœ… {test_file}: {methods} ä¸ªæµ‹è¯•æ–¹æ³•")
                self.results['test_categories']['service'] = self.results['test_categories'].get('service', 0) + methods
                self.results['total_test_files'] += 1
                self.results['total_test_methods'] += methods
            else:
                print(f"  âŒ {test_file} æ–‡ä»¶ç¼ºå¤±")
                self.results['issues'].append(f"ç¼ºå¤±æ–‡ä»¶: service/{test_file}")
    
    def validate_integration_tests(self):
        """éªŒè¯é›†æˆæµ‹è¯•"""
        print("\nğŸ”— éªŒè¯é›†æˆæµ‹è¯•...")
        
        integration_tests = [
            'FunctionCallingIntegrationTest.java'
        ]
        
        for test_file in integration_tests:
            file_path = self.test_dir / 'integration' / test_file
            if file_path.exists():
                methods = self.count_test_methods(file_path)
                print(f"  âœ… {test_file}: {methods} ä¸ªæµ‹è¯•æ–¹æ³•")
                self.results['test_categories']['integration'] = self.results['test_categories'].get('integration', 0) + methods
                self.results['total_test_files'] += 1
                self.results['total_test_methods'] += methods
            else:
                print(f"  âŒ {test_file} æ–‡ä»¶ç¼ºå¤±")
                self.results['issues'].append(f"ç¼ºå¤±æ–‡ä»¶: integration/{test_file}")
    
    def count_test_methods(self, file_path):
        """ç»Ÿè®¡æµ‹è¯•æ–¹æ³•æ•°é‡"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾ @Test æ³¨è§£
            test_methods = re.findall(r'@Test\s+(?:void\s+)?(\w+)', content)
            return len(test_methods)
        except Exception as e:
            print(f"    âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return 0
    
    def validate_build_config(self):
        """éªŒè¯æ„å»ºé…ç½®"""
        print("\nğŸ”¨ éªŒè¯æ„å»ºé…ç½®...")
        
        build_file = Path("build.gradle")
        if build_file.exists():
            with open(build_file, 'r') as f:
                content = f.read()
            
            # æ£€æŸ¥æµ‹è¯•ä¾èµ–
            required_deps = [
                'junit-jupiter',
                'mockito-core',
                'mockito-junit-jupiter',
                'mockwebserver'
            ]
            
            for dep in required_deps:
                if dep in content:
                    print(f"  âœ… ä¾èµ– {dep} å·²é…ç½®")
                else:
                    print(f"  âŒ ä¾èµ– {dep} ç¼ºå¤±")
                    self.results['issues'].append(f"ç¼ºå¤±ä¾èµ–: {dep}")
            
            # æ£€æŸ¥æµ‹è¯•é…ç½®
            if 'useJUnitPlatform()' in content:
                print("  âœ… JUnit Platform å·²é…ç½®")
            else:
                print("  âŒ JUnit Platform é…ç½®ç¼ºå¤±")
                self.results['issues'].append("ç¼ºå¤± JUnit Platform é…ç½®")
        else:
            print("  âŒ build.gradle æ–‡ä»¶ä¸å­˜åœ¨")
            self.results['issues'].append("ç¼ºå¤± build.gradle æ–‡ä»¶")
    
    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•éªŒè¯æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æµ‹è¯•éªŒè¯æŠ¥å‘Š")
        print("=" * 60)
        
        print(f"ğŸ“ æµ‹è¯•æ–‡ä»¶æ€»æ•°: {self.results['total_test_files']}")
        print(f"ğŸ§ª æµ‹è¯•æ–¹æ³•æ€»æ•°: {self.results['total_test_methods']}")
        
        print("\nğŸ“‹ åˆ†ç±»ç»Ÿè®¡:")
        for category, count in self.results['test_categories'].items():
            print(f"  {category}: {count} ä¸ªæµ‹è¯•æ–¹æ³•")
        
        if self.results['issues']:
            print(f"\nâŒ å‘ç° {len(self.results['issues'])} ä¸ªé—®é¢˜:")
            for issue in self.results['issues']:
                print(f"  - {issue}")
        else:
            print("\nâœ… æ‰€æœ‰æµ‹è¯•æ–‡ä»¶éªŒè¯é€šè¿‡!")
        
        # è®¡ç®—è¦†ç›–ç‡ä¼°ç®—
        self.estimate_coverage()
    
    def estimate_coverage(self):
        """ä¼°ç®—æµ‹è¯•è¦†ç›–ç‡"""
        print("\nğŸ“ˆ æµ‹è¯•è¦†ç›–ç‡ä¼°ç®—:")
        
        # åŸºäºæµ‹è¯•æ–¹æ³•æ•°é‡ä¼°ç®—è¦†ç›–ç‡
        expected_coverage = {
            'core': 15,      # é¢„æœŸæ ¸å¿ƒç±»æµ‹è¯•æ–¹æ³•æ•°
            'function': 20,  # é¢„æœŸå‡½æ•°æµ‹è¯•æ–¹æ³•æ•°
            'service': 8,    # é¢„æœŸæœåŠ¡æµ‹è¯•æ–¹æ³•æ•°
            'integration': 4 # é¢„æœŸé›†æˆæµ‹è¯•æ–¹æ³•æ•°
        }
        
        total_expected = sum(expected_coverage.values())
        total_actual = self.results['total_test_methods']
        
        coverage_percentage = min(100, (total_actual / total_expected) * 100)
        
        print(f"  é¢„æœŸæµ‹è¯•æ–¹æ³•æ•°: {total_expected}")
        print(f"  å®é™…æµ‹è¯•æ–¹æ³•æ•°: {total_actual}")
        print(f"  è¦†ç›–ç‡ä¼°ç®—: {coverage_percentage:.1f}%")
        
        if coverage_percentage >= 90:
            print("  ğŸ‰ æµ‹è¯•è¦†ç›–ç‡ä¼˜ç§€!")
        elif coverage_percentage >= 70:
            print("  ğŸ‘ æµ‹è¯•è¦†ç›–ç‡è‰¯å¥½!")
        else:
            print("  âš ï¸ æµ‹è¯•è¦†ç›–ç‡éœ€è¦æ”¹è¿›")

def main():
    """ä¸»å‡½æ•°"""
    validator = TestValidator()
    
    # éªŒè¯æµ‹è¯•
    success = validator.validate_all_tests()
    
    # éªŒè¯æ„å»ºé…ç½®
    validator.validate_build_config()
    
    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ æµ‹è¯•éªŒè¯å®Œæˆ! æ‰€æœ‰æµ‹è¯•æ–‡ä»¶ç»“æ„æ­£ç¡®")
        print("ğŸ’¡ å»ºè®®: åœ¨æœ‰Javaç¯å¢ƒçš„æœºå™¨ä¸Šè¿è¡Œ './gradlew test' è¿›è¡Œå®é™…æµ‹è¯•")
    else:
        print("âš ï¸ æµ‹è¯•éªŒè¯å‘ç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
    
    print("\nğŸ“š ç›¸å…³æ–‡æ¡£:")
    print("  - TESTING_GUIDE.md: è¯¦ç»†æµ‹è¯•æŒ‡å—")
    print("  - TEST_SUMMARY.md: æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
    print("  - run-tests.sh: æµ‹è¯•è¿è¡Œè„šæœ¬")

if __name__ == "__main__":
    main()
